{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset Class for Loading Images from Folders in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a187438f-049e-4143-9fc0-61abed539e0e"
   },
   "outputs": [],
   "source": [
    "class ImageFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Filter out non-directory files (like .DS_Store)\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.images = self._load_images()\n",
    "\n",
    "    def _load_images(self):\n",
    "        images = []\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                if os.path.isfile(img_path):  # Make sure it's a file, not a directory\n",
    "                    images.append((img_path, self.class_to_idx[cls]))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEucYncq5mDL"
   },
   "source": [
    "### Data Augmentation, Normalization, and Dataloading for Image Classification in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJ32rRyFTSW_",
    "outputId": "3a9efa49-30e1-4f61-b3d0-63864567fadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),  # Randomly resize and crop the image to 224x224\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize the image to 256x256\n",
    "        transforms.CenterCrop(224),  # Crop the center 224x224 portion\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the correct path to your dataset\n",
    "data_dir = '/content/drive/My Drive/NWPU-RESISC45-classification/'  # Root dataset directory\n",
    "\n",
    "# Load datasets - point directly to the main dataset directory (containing class folders)\n",
    "image_datasets = {\n",
    "    'train': ImageFolderDataset(data_dir, data_transforms['train']),\n",
    "    'val': ImageFolderDataset(data_dir, data_transforms['val'])  # Assuming validation data is the same structure\n",
    "}\n",
    "\n",
    "# Create dataloaders to feed the data into the model\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "# Get dataset sizes and class names\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Fine-Tuned ResNet50 Model with Custom Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A19EnAEATmJj"
   },
   "outputs": [],
   "source": [
    "# Function to create a ResNet50 model for fine-tuning\n",
    "def create_model(num_classes):\n",
    "    # Load the pre-trained ResNet50 model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Freeze the earlier layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the fully connected layer to match the number of classes in your dataset\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)  # Modify the last layer\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5k0DFpuO5u7U"
   },
   "source": [
    "### Training and Validation Function for Fine-Tuning ResNet50 in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d-FNQXOUT1iN"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # Backward pass + optimization in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model with the best validation accuracy\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    model.load_state_dict(best_model_wts)  # Load the best model weights\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function to Fine-Tune ResNet50 and Save the Best Model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMSVWlsiUF8B",
    "outputId": "98f50449-8195-400f-acbc-9839f2bcc148"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 181MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 2.0853 Acc: 0.5574\n",
      "val Loss: 1.1071 Acc: 0.7517\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 1.2434 Acc: 0.6948\n",
      "val Loss: 0.8644 Acc: 0.7766\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 1.0773 Acc: 0.7200\n",
      "val Loss: 0.7601 Acc: 0.7928\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.9985 Acc: 0.7316\n",
      "val Loss: 0.7091 Acc: 0.8024\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.9467 Acc: 0.7412\n",
      "val Loss: 0.6727 Acc: 0.8087\n",
      "\n",
      "Best val Acc: 0.8087\n"
     ]
    }
   ],
   "source": [
    "# Main function to run the experiment\n",
    "def run_experiment():\n",
    "    num_classes = len(class_names)  # Get the number of classes for classification\n",
    "    model = create_model(num_classes).to(device)  # Create the ResNet50 model and move it to GPU or CPU\n",
    "    criterion = nn.CrossEntropyLoss()  # Define the loss function (CrossEntropy for classification)\n",
    "\n",
    "    # Define optimizer and learning rate scheduler\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # Train the model using the train_model function\n",
    "    model = train_model(model, criterion, optimizer, scheduler, num_epochs=7)\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    torch.save(model.state_dict(), 'resnet50_finetuned_best.pth')\n",
    "\n",
    "# Run the experiment when the script is executed\n",
    "if __name__ == \"__main__\":\n",
    "    run_experiment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Epoch | Train Loss | Train Accuracy | Val Loss | Val Accuracy |\n",
    "|-------|------------|----------------|----------|--------------|\n",
    "| 0     | 2.0853     | 0.5574         | 1.1071   | 0.7517       |\n",
    "| 1     | 1.2434     | 0.6948         | 0.8644   | 0.7766       |\n",
    "| 2     | 1.0773     | 0.7200         | 0.7601   | 0.7928       |\n",
    "| 3     | 0.9985     | 0.7316         | 0.7091   | 0.8024       |\n",
    "| 4     | 0.9467     | 0.7412         | 0.6727   | 0.8087       |\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
